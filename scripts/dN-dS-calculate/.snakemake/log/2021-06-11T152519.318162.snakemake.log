Building DAG of jobs...
Using shell: /bin/bash
Provided cores: 1 (use --cores to define parallelism)
Rules claiming more threads will be scaled down.
Job counts:
	count	jobs
	1	Nuc_AA_FnaF_of_diverGene
	1	all
	2
Select jobs to execute...

[Fri Jun 11 15:25:19 2021]
rule Nuc_AA_FnaF_of_diverGene:
    input: /shared/liuhj/HP/process/Person_core_genome/P1
    output: /shared/liuhj/HP/process/dN-dS-caculate/P1
    jobid: 1
    wildcards: person=P1

python /shared/liuhj/HP/scripts/HP-microevolution/scripts/dN-dS-calculate/nuc_aa-seq-from-roaryOutput.py  -i P1 -r /shared/liuhj/HP/process/Person_core_genome/P1  -p /shared/liuhj/HP/process/assembly/prokka  -o  /shared/liuhj/HP/process/dN-dS-caculate/P1
[Fri Jun 11 15:25:19 2021]
Finished job 1.
1 of 2 steps (50%) done
Select jobs to execute...

[Fri Jun 11 15:25:19 2021]
localrule all:
    input: /shared/liuhj/HP/process/dN-dS-caculate/P1
    jobid: 0

[Fri Jun 11 15:25:19 2021]
Finished job 0.
2 of 2 steps (100%) done
Complete log: /shared/liuhj/HP/scripts/HP-microevolution/scripts/dN-dS-calculate/.snakemake/log/2021-06-11T152519.318162.snakemake.log
